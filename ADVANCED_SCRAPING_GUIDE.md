# üöÄ Guia Avan√ßado de Scraping - GodOfPrompt.ai

## üìã Vis√£o Geral da Estrat√©gia

Este guia documenta a estrat√©gia completa para evitar bloqueios e otimizar performance no scraping do GodOfPrompt.ai, incluindo bypass de paywall e extra√ß√£o do conte√∫do completo dos prompts.

### üéØ Objetivos
1. **Evitar Bloqueios**: T√©cnicas avan√ßadas de anti-detec√ß√£o
2. **Otimizar Performance**: Scraping eficiente e controlado
3. **Bypass de Paywall**: Automa√ß√£o de login e sess√£o persistente
4. **Extra√ß√£o Completa**: Conte√∫do detalhado de cada prompt
5. **Monitoramento**: Sistema adaptativo em tempo real

## üõ°Ô∏è Sistema Anti-Bloqueio

### 1. Anti-Detec√ß√£o Avan√ßada

#### Driver Configuration (`anti_blocking_strategy.py`)
```python
# User-Agents rotativos
user_agents = [
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36...",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36..."
]

# Dimens√µes de janela vari√°veis
width = random.randint(1366, 1920)
height = random.randint(768, 1080)

# Anti-detec√ß√£o completa
chrome_options.add_argument("--disable-blink-features=AutomationControlled")
chrome_options.add_argument("--disable-images")  # Performance
chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
```

#### Delays Adaptativos
- **Base**: 2-8 segundos entre requisi√ß√µes
- **Adaptativo**: Aumenta ap√≥s erros, diminui ap√≥s sucessos
- **Jitter**: Aleatoriedade para mascarar padr√µes
- **Backoff Exponencial**: Delays progressivos ap√≥s bloqueios

#### Circuit Breaker
- Pausa autom√°tica ap√≥s 5 falhas consecutivas
- Timeout de recupera√ß√£o: 5 minutos
- Prote√ß√£o contra falhas em cascata

### 2. T√©cnicas de Bypass

#### Headers Realistas
```python
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)...',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9...',
    'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate, br',
    'DNT': '1',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}
```

#### Comportamento Humano
- Scroll simulado para carregar conte√∫do lazy-loaded
- Pausas vari√°veis entre a√ß√µes
- Intera√ß√µes realistas com elementos
- Movimento de mouse simulado

## ‚ö° Otimiza√ß√£o de Performance

### 1. Processamento Paralelo (`performance_optimizer.py`)

#### Configura√ß√£o Otimizada
```python
config = {
    'batch_size': 3,        # Lotes pequenos para controle
    'max_workers': 2,       # Concorr√™ncia conservadora
    'max_memory_mb': 1024,  # Limite de mem√≥ria
    'use_cache': True,      # Cache inteligente
    'monitor_resources': True
}
```

#### Cache Inteligente
- Cache v√°lido por 24 horas
- M√°ximo 50 categorias em cache
- Verifica√ß√£o autom√°tica de validade
- Limpeza inteligente de cache antigo

#### Monitoramento de Recursos
```python
# Limites autom√°ticos
max_memory_mb = 1024
max_cpu_percent = 80

# Limpeza autom√°tica quando necess√°rio
if memory_usage > threshold:
    gc.collect()
    time.sleep(5)
```

### 2. M√©tricas Detalhadas

#### Performance Tracking
- Prompts por segundo
- P√°ginas por minuto
- Taxa de sucesso por categoria
- Tempo m√©dio de resposta
- Uso de recursos em tempo real

#### Relat√≥rios Autom√°ticos
- Estat√≠sticas por categoria
- Identifica√ß√£o de gargalos
- Recomenda√ß√µes autom√°ticas
- Estimativa de tempo restante

## üîê Sistema de Login Autom√°tico

### 1. Automa√ß√£o Robusta (`login_automation.py`)

#### Caracter√≠sticas
- **M√∫ltiplas Tentativas**: At√© 3 tentativas com backoff
- **Sess√£o Persistente**: Cache de cookies por 2 horas
- **Valida√ß√£o Cont√≠nua**: Teste autom√°tico de sess√£o
- **Fallback**: Modo headless ap√≥s primeira tentativa

#### Detec√ß√£o de Sucesso
```python
success_indicators = ['/dashboard', 'premium', 'logout', 'profile']
```

#### Sess√£o Reutiliz√°vel
```python
# Salva cookies e headers automaticamente
session_manager.save_session(cookies, headers)

# Recupera sess√£o v√°lida
session = login_system.get_authenticated_session()
```

### 2. Bypass de Paywall

#### Estrat√©gia
1. Login autom√°tico na primeira execu√ß√£o
2. Persist√™ncia de sess√£o entre execu√ß√µes
3. Valida√ß√£o cont√≠nua durante scraping
4. Re-login autom√°tico se necess√°rio

#### Valida√ß√£o de Sess√£o
```python
def test_session_validity(test_url):
    response = session.get(test_url)
    return 'signin' not in response.url
```

## üìä Sistema de Monitoramento

### 1. Monitoramento em Tempo Real (`monitoring_system.py`)

#### M√©tricas Principais
- **Taxa de Sucesso**: M√≠nimo 70%
- **Tempo de Resposta**: M√°ximo 30s
- **Erros Consecutivos**: M√°ximo 5
- **Uso de Recursos**: CPU < 85%, RAM < 1GB

#### Alertas Autom√°ticos
```python
alert_types = [
    'BLOQUEIO_DETECTADO',    # Keywords de bloqueio encontradas
    'ALTA_TAXA_ERRO',        # > 50% de erro
    'RESPOSTA_LENTA',        # > 30s de resposta
    'MEMORIA_ALTA'           # > limite de mem√≥ria
]
```

### 2. Adapta√ß√£o Autom√°tica

#### Controlador Adaptativo
- **Delay Din√¢mico**: Ajuste baseado no status
- **Pausa Inteligente**: Para quando necess√°rio
- **Troca de User-Agent**: Ap√≥s m√∫ltiplas falhas
- **Recomenda√ß√µes**: Sugest√µes autom√°ticas

#### Estados do Sistema
- `HEALTHY`: Funcionamento normal
- `WARNING`: Problemas menores detectados
- `CRITICAL`: Alta taxa de erro
- `BLOCKED`: Poss√≠vel bloqueio detectado

## üîç Extra√ß√£o de Conte√∫do Individual

### 1. Scraper de Prompts (`prompt_content_scraper.py`)

#### Estrat√©gia Multi-M√©todo
1. **Requests + BeautifulSoup**: M√©todo r√°pido
2. **Selenium**: Fallback para conte√∫do JavaScript
3. **FireCrawl**: Bypass profissional (opcional)

#### Extra√ß√£o Inteligente
```python
content_selectors = {
    'prompt_text': ['div[class*="prompt-text"]', 'pre', 'code'],
    'title': ['h1', 'h2', '.prompt-title'],
    'description': ['.description', '.prompt-description'],
    'tags': ['.tag', '.badge', '.chip']
}
```

#### Estrutura de Dados
```python
@dataclass
class PromptData:
    id: str
    title: str
    prompt_text: str
    description: str
    tags: List[str]
    category: str
    estimated_tokens: int
    extracted_at: str
    success: bool
```

### 2. Processamento em Paralelo

#### Configura√ß√£o Segura
- **Max Workers**: 5 (conservador)
- **Batch Size**: 10 URLs por lote
- **Timeout**: 30s por URL
- **Retry**: At√© 3 tentativas

#### Controle de Recursos
```python
# Pausas estrat√©gicas
time.sleep(5)  # Entre lotes
time.sleep(1)  # Entre URLs individuais

# Monitoramento de mem√≥ria
if memory_usage > 800MB:
    gc.collect()
```

## üî• Integra√ß√£o FireCrawl

### 1. Vantagens do FireCrawl (`firecrawl_integration.py`)

#### Recursos Avan√ßados
- **Bypass Autom√°tico**: Anti-bot profissional
- **JavaScript Rendering**: Conte√∫do din√¢mico
- **Rate Limiting**: Autom√°tico
- **Formato M√∫ltiplo**: HTML, Markdown, texto

#### Configura√ß√£o Otimizada
```python
scrape_options = {
    'formats': ['markdown', 'html'],
    'onlyMainContent': True,
    'waitFor': 3000,  # 3s para JavaScript
    'actions': [
        {'type': 'wait', 'milliseconds': 2000},
        {'type': 'scroll', 'direction': 'down'},
        {'type': 'click', 'selector': '.modal-close', 'optional': True}
    ]
}
```

### 2. Scraper H√≠brido

#### Estrat√©gia Combinada
1. **FireCrawl**: URLs problem√°ticas
2. **Tradicional**: URLs simples
3. **Fallback Autom√°tico**: Se um m√©todo falha

#### An√°lise de Custo
- **FireCrawl**: ~$0.001 por URL
- **Tradicional**: Gratuito
- **H√≠brido**: Melhor custo-benef√≠cio

## üìã Fluxo de Execu√ß√£o Completo

### 1. Prepara√ß√£o
```bash
# Instalar depend√™ncias
pip install -r requirements.txt

# Configurar credenciais
export GODOFPROMPT_EMAIL="seu_email@exemplo.com"
export GODOFPROMPT_PASSWORD="sua_senha"
export FIRECRAWL_API_KEY="sua_api_key"  # Opcional
```

### 2. Execu√ß√£o Fase 1: Extra√ß√£o de Links
```python
# Extra√ß√£o otimizada de links
from performance_optimizer import OptimizedScraper

scraper = OptimizedScraper(config={
    'batch_size': 2,
    'max_workers': 2,
    'use_cache': True
})

links_data = scraper.extract_all_categories(categories, extract_func)
```

### 3. Execu√ß√£o Fase 2: Extra√ß√£o de Conte√∫do
```python
# Setup do sistema completo
login_system = create_login_system(email, password)
monitor = SystemMonitor()
content_extractor = PromptContentExtractor(login_system, monitor)

# Login e extra√ß√£o
login_system.perform_login()
all_prompts = content_extractor.extract_multiple_prompts(all_links)
```

### 4. Monitoramento Cont√≠nuo
```python
# Sistema de monitoramento
monitoring_system = create_monitoring_system()
monitoring_system['start']()

# Adapta√ß√£o autom√°tica
controller = AdaptiveController(monitor)
adaptive_delay = controller.get_adaptive_delay()
```

## üìà M√©tricas de Sucesso

### 1. KPIs Principais
- **Taxa de Sucesso**: > 85%
- **Velocidade**: > 100 prompts/hora
- **Uptime**: > 95% sem bloqueios
- **Qualidade**: > 90% com conte√∫do completo

### 2. Limites Operacionais
- **Requisi√ß√µes/Minuto**: < 60
- **P√°ginas/Categoria**: < 50
- **Concurrent Workers**: ‚â§ 5
- **Tempo/Prompt**: < 30s

## üîß Troubleshooting

### 1. Problemas Comuns

#### Bloqueios Detectados
```python
# Sinais de alerta
block_keywords = ['blocked', 'captcha', 'rate limit', 'access denied']

# A√ß√µes corretivas
- Aumentar delays (x4)
- Trocar User-Agent
- Pausar por 10 minutos
- Usar FireCrawl
```

#### Performance Baixa
```python
# Otimiza√ß√µes
- Reduzir max_workers para 2
- Aumentar batch delays para 10s
- Desabilitar imagens no Chrome
- Usar cache agressivamente
```

#### Falhas de Login
```python
# Solu√ß√µes
- Verificar credenciais
- Usar modo n√£o-headless
- Capturar screenshots
- Aumentar timeouts
```

### 2. Logs e Debug

#### Configura√ß√£o de Logs
```python
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('scraping.log'),
        logging.StreamHandler()
    ]
)
```

#### Debug Avan√ßado
- Screenshots autom√°ticos em falhas
- Dump de HTML para an√°lise
- M√©tricas detalhadas por categoria
- Rastreamento de recursos

## üéØ Recomenda√ß√µes Finais

### 1. Configura√ß√£o Recomendada
```python
production_config = {
    'batch_size': 2,
    'max_workers': 2,
    'delays': {'min': 5, 'max': 15},
    'max_pages_per_category': 30,
    'use_cache': True,
    'monitor_resources': True,
    'session_timeout': 7200,  # 2 horas
    'max_retries': 3
}
```

### 2. Melhores Pr√°ticas
- **Come√ßar Devagar**: Teste com 1-2 categorias
- **Monitorar Sempre**: Use sistema de alertas
- **Respeitar Limites**: N√£o sobrecarregar o servidor
- **Cache Inteligente**: Evitar re-processamento
- **Backup de Sess√£o**: Persistir estado

### 3. Expans√£o Futura
- **Proxy Rotation**: Para maior anonimato
- **Distributed Scraping**: M√∫ltiplas IPs
- **ML-Based Adaptation**: Aprendizado autom√°tico
- **API Integration**: Usar APIs quando dispon√≠veis

---

## üìä Resumo de Arquivos

| Arquivo | Prop√≥sito | Funcionalidades Principais |
|---------|-----------|---------------------------|
| `anti_blocking_strategy.py` | Anti-detec√ß√£o | User-agents rotativos, delays adaptativos, circuit breaker |
| `performance_optimizer.py` | Performance | Cache, processamento paralelo, m√©tricas |
| `monitoring_system.py` | Monitoramento | Alertas, adapta√ß√£o, dashboard |
| `login_automation.py` | Bypass paywall | Login autom√°tico, sess√£o persistente |
| `prompt_content_scraper.py` | Extra√ß√£o conte√∫do | Multi-m√©todo, estrutura de dados |
| `firecrawl_integration.py` | Bypass profissional | FireCrawl, scraper h√≠brido |

---

**üéØ Resultado Esperado**: Sistema robusto capaz de extrair milhares de prompts com taxa de sucesso > 85% e sem bloqueios.